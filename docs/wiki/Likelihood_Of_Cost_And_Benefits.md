<div style="font-family: 'Segoe UI', Arial, sans-serif; line-height: 1.6; color: #333;">
<h3>The Likelihood Score: Calibrated Probability for <a href="/w/page/156187122/cost-benefit%20analysis">Cost-Benefit Analysis</a></h3>
<p>In the Idea Stock Exchange, a <strong>Likelihood Score</strong> is not a subjective guess, a slider, or a gut feeling. It is a <strong>nested belief</strong> that must earn its probability through structured reasoning.</p>
<p>In any Cost-Benefit Analysis (CBA), the final contribution of a line item is its <strong>Expected Value</strong>:</p>
<blockquote style="text-align: center; margin: 1.5em 0; padding: 1em; background-color: #f8f9fa; border-left: 4px solid #0366d6;"><em>Predicted Impact &times; Likelihood Score = Expected Value</em></blockquote>
<p>For example, a predicted benefit of <strong>$1,000,000</strong> with a <strong>50%</strong> Likelihood Score contributes exactly <strong>$500,000</strong> to the final decision. A catastrophic risk of <strong>$10M</strong> with a <strong>10%</strong> likelihood subtracts <strong>$1M</strong>. This ensures that high-impact but low-probability outcomes do not distort the analysis, and that uncertainty is accounted for mathematically.</p>
<h3>How the Score is Generated: A Competition of Reasons</h3>
<p>A Likelihood Score is derived from a transparent competition between arguments using <a href="/w/page/159300543/ReasonRank">ReasonRank</a>. The system does not ask users to "vote" on a probability; it asks them to <strong>argue</strong> for one.</p>
<ol>
<li><strong>The Likelihood is a "Conclusion"</strong> </li>
<ol type="a">
<li>When a user adds a cost or benefit (e.g., &ldquo;This project will save $1M&rdquo;), they are implicitly making a second claim: <em>&ldquo;There is an X% chance this will happen.&rdquo;</em> This probability claim becomes a nested belief node <a href="/w/page/21956623/A%20page%20of%20one's%20own">with its own page</a>. Multiple competing estimates (e.g., &ldquo;30%&rdquo;, &ldquo;50&ndash;60%&rdquo;, &ldquo;90%+&rdquo;) can coexist and compete for dominance.</li>
</ol>
<li><strong>Arguments Build the Score (The Tree)</strong> </li>
<ol type="a">
<li>Users and AI agents submit pro/con arguments that branch into further sub-arguments, forming a recursive &ldquo;argument tree&rdquo; for each proposed likelihood. A high score requires strong supporting arguments and weak opposing ones.</li>
<li>High-quality arguments typically appeal to <strong>Reference Class Forecasting</strong> and related super-forecasting techniques. For example: </li>
<ul>
<li><strong>Base Rates:</strong> &ldquo;In 100 similar bridge projects, 60% went over budget.&rdquo;</li>
<li><strong>Historical Data:</strong> &ldquo;When inflation exceeds 5%, this asset class drops in value 80% of the time.&rdquo;</li>
<li><strong>Falsifiable Assumptions:</strong> &ldquo;This outcome assumes the law passes; currently, it has only 30% polling support.&rdquo;</li>
</ul>
</ol>
<li><strong>ReasonRank Scoring</strong> </li>
<ol type="a">
<li>The system scores every argument and sub-argument using three recursive metrics: </li>
<ol type="i">
<li><a href="/w/page/159300627/Truth%20Scores"><strong>Truth</strong></a>: Is the underlying evidence factually accurate?</li>
<li><a href="/w/page/159338766/Linkage%20Scores"><strong>Linkage</strong></a>: How strongly does this reasoning connect to <em>this specific</em> prediction? (e.g., A weak analogy like &ldquo;twice the size = twice the cost&rdquo; has low linkage if data shows nonâ€‘linear scaling.)</li>
<li><a href="/w/page/162731388/Importance%20Score"><strong>Importance</strong></a>: How much does this argument move the probability?</li>
</ol> </ol>
<li><strong>The "Winning" Likelihood</strong> </li>
<ol type="a">
<li>The Likelihood Score is <strong>not an average</strong> and <strong>not a vote</strong>. It is the specific probability (or range) supported by the <strong>strongest surviving argument tree</strong>. </li>
<ul>
<li>If arguments for a &ldquo;90% likelihood&rdquo; rely on wishful thinking (low Truth/Linkage), that score decays.</li>
<li>If arguments for a &ldquo;50% likelihood&rdquo; are backed by solid reference classes and survive scrutiny, <strong>50% becomes the active Likelihood Score</strong>.</li>
</ul>
</ol> </ol>
<h3>Why This Matters</h3>
<ul>
<li><strong>Combats <a href="/w/page/21956934/bias">Optimism Bias</a>:</strong> Proponents cannot just claim a &ldquo;Best Case Scenario.&rdquo; They must build a surviving argument tree justifying why that outcome is <em>probable</em>.</li>
<li><strong>Standardizes Comparisons:</strong> A 10% chance of $10M and a 100% chance of $1M are treated as equal expected value ($1M).</li>
<li><strong>Rejects Intuition:</strong> To reject this method is to claim that human intuition handles complexity better than mathematical expected value&mdash;a claim that is demonstrably false.</li>
</ul>
<p><strong>The Blunt Rule:</strong> Impacts don't count unless their probabilities survive attack.</p>
</div>
<p>&nbsp;</p>
