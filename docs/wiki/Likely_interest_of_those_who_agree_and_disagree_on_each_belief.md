<p>&nbsp;</p>
<h1>Interest Analysis: Score the "Why" Behind Beliefs</h1>
<p style="text-align: right;"><strong><a href="/w/page/159323433/One%20Page%20Per%20Topic">Topic</a>:</strong> <span style="font-size: 13px;"><a href="/w/page/21957511/Explanation">ISE Framework</a> &gt; <a href="/w/page/156186840/automate%20conflict%20resolution">Conflict Resolution</a> &gt; <a href="/w/page/159301140/Interests">Interest Analysis</a></span></p>
<p><strong>The Proposal:</strong> Stop debating only positions ("what do you want?") and start scoring motivations ("why do you want it?"). For every belief, we generate two scores that make conflict measurable instead of vibes-based:</p>
<ol>
<li><strong>Linkage Accuracy (0-100):</strong> Are we right about which interests motivate which groups?</li>
<li><strong>Interest Validity (0-100):</strong> Even if it's real, how legitimate is that interest compared to others?</li>
</ol> 
<hr />
<h1>What We Build: The Interest Profile</h1>
<p>Every belief gets an <strong>Interest Profile</strong> that's editable, evidence-driven, and auditable:</p>
<ul>
<li><strong>Supporter interests:</strong> Why people agree</li>
<li><strong>Opponent interests:</strong> Why people disagree</li>
<li><strong>% breakdown:</strong> Estimated share of each group driven by each interest</li>
<li><strong>Two scores:</strong> Linkage Accuracy + Interest Validity</li>
</ul>
<p>The point isn't to "purify" debate. It's to <strong>make motives testable</strong> and <strong>make compromises buildable</strong>.</p>
<p><em>See: <a href="/w/page/159301140/Interests">Stakeholder Interest Analysis Framework</a></em></p>
<hr />
<h1>Score 1: Linkage Accuracy (Stop Strawman Motives)</h1>
<p>People constantly argue by guessing the other side's motives ("they just hate X"). <strong>Linkage Accuracy</strong> puts that guess on a leash: if you claim a motive, you need <a href="/w/page/159353568/Evidence">evidence</a>.</p>
<p><strong>What drives Linkage Accuracy:</strong></p>
<ul>
<li><strong>Evidence strength:</strong> Surveys, interviews, public statements (<a href="/w/page/159353568/Evidence">Evidence tiers</a>)</li>
<li><strong>Behavioral match:</strong> Do actions align with the stated motive?</li>
<li><strong>Revealed preferences:</strong> Votes, donations, spending, time allocation</li>
<li><strong>Expert validation:</strong> Do credible analysts confirm it?</li>
<li><strong>Historical consistency:</strong> Does this pattern repeat in similar groups/context?</li>
</ul>
<p><strong>Example: Tax Policy</strong></p>
<table border="1" cellpadding="8">
<thead> 
<tr>
<th><strong>Group</strong></th> <th><strong>Interest</strong></th> <th><strong>% Motivated</strong></th> <th><strong>Linkage Accuracy</strong></th>
</tr>
</thead> 
<tbody>
<tr>
<td rowspan="3">Tax Increase Supporters</td>
<td>Economic equality</td>
<td>40%</td>
<td>85 (strong surveys)</td>
</tr>
<tr>
<td>Public services funding</td>
<td>35%</td>
<td>90 (behaviorally consistent)</td>
</tr>
<tr>
<td>Wealth redistribution</td>
<td>25%</td>
<td>70 (disputed evidence)</td>
</tr>
<tr>
<td rowspan="3">Tax Decrease Supporters</td>
<td>Economic growth</td>
<td>45%</td>
<td>75 (mixed evidence)</td>
</tr>
<tr>
<td>Personal financial benefit</td>
<td>30%</td>
<td>65 (revealed preference)</td>
</tr>
<tr>
<td>Limited government</td>
<td>25%</td>
<td>80 (ideological consistency)</td>
</tr>
</tbody>
</table>
<p>Scores update as users add <a href="/Reasons">arguments</a> and <a href="/w/page/159353568/Evidence">evidence</a>: better data raises confidence; speculation drops it.</p>
<p><em>See: <a href="/w/page/159338766/Linkage%20Scores">Evidence-to-Conclusion Linkage Methodology</a></em></p>
<hr />
<h1>Score 2: Interest Validity (Not All Motives Are Equal)</h1>
<p>Some interests are about safety or survival. Some are about status. Some are about domination. <strong>Validity</strong> ranks interests so debates stop treating everything as equally sacred.</p>
<p><strong>Maslow-Informed Validity Framework:</strong></p>
<table border="1" cellpadding="8">
<thead> 
<tr>
<th><strong>Maslow Level</strong></th> <th><strong>Validity Range</strong></th> <th><strong>Examples</strong></th>
</tr>
</thead> 
<tbody>
<tr>
<td>Physiological</td>
<td>85-100</td>
<td>Food, shelter, health, survival</td>
</tr>
<tr>
<td>Safety</td>
<td>70-85</td>
<td>Economic security, protection from harm</td>
</tr>
<tr>
<td>Belonging</td>
<td>50-70</td>
<td>Community, family, social connection</td>
</tr>
<tr>
<td>Esteem</td>
<td>40-60</td>
<td>Respect, recognition, status</td>
</tr>
<tr>
<td>Self-Actualization</td>
<td>30-50</td>
<td>Growth, creativity, purpose</td>
</tr>
<tr>
<td>Invalid</td>
<td>0-20</td>
<td>Domination, tribal winning, pretextual claims</td>
</tr>
</tbody>
</table>
<p><strong>Within-level ranking criteria:</strong></p>
<ol>
<li><strong>Impact scope:</strong> How many people, how severely affected</li>
<li><strong>Reversibility:</strong> Irreversible harms rank higher</li>
<li><strong>Alternative satisfaction:</strong> Fewer alternatives means higher priority</li>
<li><strong>Universal test:</strong> What if everyone pursued it?</li>
<li><strong>Reciprocity:</strong> Would you accept it applied to you?</li>
</ol>
<p><em>See: <a href="/Insisting%20on%20Objective%20Criteria">Insisting on Objective Criteria</a></em></p>
<hr />
<h1>"Ugly" Interests Don't Get Ignored&mdash;They Get Bad Scores</h1>
<p>We don't pretend bad motivations don't exist. We just stop letting them run the show. Interests that fail ethical tests get <strong>de-weighted</strong> (typically 0-20):</p>
<ul>
<li><strong>Domination interests:</strong> Universal application creates perpetual conflict</li>
<li><strong>Zero-sum tribal winning:</strong> "I want them to lose" isn't a public goal</li>
<li><strong>Pretextual motives:</strong> Stated reason contradicts behavior</li>
<li><strong>Manufactured interests:</strong> Based on misinformation, no <a href="/w/page/159353568/Evidence">evidence base</a></li>
</ul>
<p><em>See: <a href="/w/page/21960078/truth">Truth Scoring System</a>, <a href="/w/page/21956934/bias">Cognitive Bias Detection</a></em></p>
<hr />
<h1>Debating the Scores</h1>
<p><strong>Arguments supporting linkage/validity:</strong></p>
<ul>
<li>Survey data, behavioral evidence, expert analysis</li>
<li>Historical patterns, revealed preferences</li>
<li>Universal application produces beneficial results</li>
<li>Satisfying interest improves wellbeing</li>
</ul>
<p><strong>Arguments challenging linkage/validity:</strong></p>
<ul>
<li>Stated interest contradicts actual behavior</li>
<li>Confounding factors mask real motivation</li>
<li>Universal application creates problems</li>
<li>Pursuing interest harms others, violates reciprocity</li>
</ul>
<p>Scored using <a href="/w/page/159300543/ReasonRank">ReasonRank</a>, updating as new <a href="/w/page/159353568/Evidence">evidence</a> emerges.</p>
<p><em>See: <a href="/w/page/156187122/cost-benefit%20analysis">Cost-Benefit Analysis Framework</a></em></p>
<hr />
<h1>Finding Shared Interests</h1>
<p>Interest profiling reveals where opposing groups share motivations&mdash;foundation for <a href="/w/page/162560439/Compromise">compromise</a>.</p>
<p><strong>Example: Healthcare Reform</strong></p>
<table border="1" cellpadding="8">
<thead> 
<tr>
<th><strong>Interest Type</strong></th> <th><strong>Shared by Both Sides</strong></th>
</tr>
</thead> 
<tbody>
<tr>
<td>High Validity (85+)</td>
<td>Access to care when sick, affordability, quality treatment</td>
</tr>
<tr>
<td>Medium Validity (60-85)</td>
<td>System sustainability, innovation incentives</td>
</tr>
<tr>
<td>Conflicting</td>
<td>Government control vs. market freedom (compatibility analysis needed)</td>
</tr>
</tbody>
</table>
<p>Build solutions on high-validity shared interests first.</p>
<p><em>See: <a href="/Inventing%20Options%20for%20Mutual%20Gain">Inventing Options for Mutual Gain</a></em></p>
<hr />
<h1>Automation: Faster Mapping, Less Duplication</h1>
<p>Once interests are "data," we automate the boring work and save humans for the hard parts:</p>
<ul>
<li><strong>NLP extraction:</strong> Pulls interests from submissions</li>
<li><strong>Semantic clustering:</strong> Merges duplicates/synonyms</li>
<li><strong>Compatibility analysis:</strong> Maps overlaps and trade-offs</li>
<li><strong>Visualizations:</strong> Generates matrices, heatmaps, trade-off curves</li>
<li><strong>Dynamic updates:</strong> Recalculates scores when new <a href="/w/page/159353568/Evidence">evidence</a>/<a href="/Reasons">arguments</a> appear</li>
</ul>
<p><strong>Output:</strong> System surfaces high-accuracy + high-validity shared interests as foundation for <a href="/w/page/162560439/Compromise">compromise</a> and actionable options.</p>
<p><em>See: <a href="/Interests%20Code">Interest Analysis Implementation Code</a></em></p>
<hr />
<h1>Multi-Dimensional Interest Profiles</h1>
<p>Each interest gets four complementary scores:</p>
<ul>
<li><strong>Need Intensity (N):</strong> How critical? (Maslow level sets baseline)</li>
<li><strong>Motivational Depth (D):</strong> Connection to core <a href="/w/page/162560400/Values%20of%20those%20who%20agree%20and%20disagree">values</a></li>
<li><strong>Relational Complexity (R):</strong> Network effects with other interests</li>
<li><strong>Contextual Relevance (C):</strong> <a href="/w/page/159338766/Linkage%20Scores">Linkage strength</a> to specific belief</li>
</ul>
<hr />
<h1>How to Contribute</h1>
<ol>
<li><strong>Suggest interests</strong> for a belief (supporter + opponent)</li>
<li><strong>Estimate percentages</strong> (dominant vs. fringe motivations)</li>
<li><strong>Add evidence</strong> supporting/challenging the linkage</li>
<li><strong>Argue validity</strong> using ethical + practical criteria</li>
<li><strong>Flag shared interests</strong> to build <a href="/w/page/162560439/Compromise">compromise</a> options</li>
</ol>
<p><em>See: <a href="/Brainstorming%20Interests%20for%20Policy%20Debates">Brainstorming Interests for Policy Debates</a></em></p>
<hr />
<h1>Why This Matters</h1>
<p>Scoring the <strong>why</strong> behind beliefs turns tribal argument into structured problem-solving: less mind-reading, more <a href="/w/page/159353568/Evidence">evidence</a>, clearer priorities, and <a href="/w/page/162560439/Compromise">compromise</a> built on real shared interests.</p>
<p><em>See: <a href="/Separating%20People%20from%20the%20Problem">Separating People from the Problem</a>, <a href="/w/page/156186840/automate%20conflict%20resolution">Automated Conflict Resolution</a></em></p>
<hr />
<h1>Related Resources</h1>
<ul>
<li><a href="/w/page/159301140/Interests">Stakeholder Interest Analysis Framework</a></li>
<li><a href="/Applying%20'Getting%20to%20Yes'%20Principles">Applying "Getting to Yes" Principles</a></li>
<li><a href="/w/page/162560400/Values%20of%20those%20who%20agree%20and%20disagree">Values Framework</a></li>
<li><a href="/Insisting%20on%20Objective%20Criteria">Insisting on Objective Criteria</a></li>
<li><a href="/w/page/159338766/Linkage%20Scores">Linkage Scoring Methodology</a></li>
</ul>
<hr />
<h1>Contribute</h1>
<p><strong><a href="/w/page/160433328/Contact%20Me">Contact me</a></strong> to help develop interest analysis tools or map interests for specific beliefs.</p>
<p><strong><a href="https://github.com/myklob/ideastockexchange">GitHub</a></strong> for technical implementation.</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2>The Core Problem: The "Consensus Gap"</h2>
<p>We currently treat every conflict as a unique, manual labor-intensive event. This is a failure of system design. When we don't drive toward consensus on "little" conflicts (the underlying motives), they aggregate into "big" conflicts (cultural and political gridlock).</p>
<p><strong>Why we must automate:</strong></p>
<ul>
<li>
<p><strong>Scalability:</strong> Human mediators cannot handle millions of daily digital micro-conflicts.</p>
</li>
<li>
<p><strong>Bias Neutralization:</strong> Algorithms don't have "skin in the game" and can apply the <strong>Validity Framework</strong> without tribal favoritism.</p>
</li>
<li>
<p><strong>Speed:</strong> Real-time policy adjustments require real-time interest mapping, not decadal shifts in public opinion.</p>
</li>
</ul>
<hr />
<h2>How the Interest Profile Drives Resolution</h2>
<p>The <strong>Interest Profile</strong> is the "API" for conflict resolution. Instead of debating the belief, we debug the profile.</p>
<h3>1. Linkage Accuracy: The "Anti-Strawman" Filter</h3>
<p>Most conflict is fueled by <strong>imputed motives</strong>. We assume our opponents have the worst possible reasons for their beliefs.</p>
<ul>
<li>
<p><strong>The Fix:</strong> By requiring evidence (surveys, behavioral data) for any claimed interest, we delete "phantom conflicts" based on misinformation.</p>
</li>
<li>
<p><strong>Metric:</strong> If the <strong>Linkage Accuracy</strong> is low, the argument is flagged as speculative and removed from the resolution path.</p>
</li>
</ul>
<h3>2. Interest Validity: The Hierarchy of Needs</h3>
<p>Conflict resolution often stalls because we treat "I want to survive" (High Validity) as equal to "I want my team to win" (Low Validity).</p>
<ul>
<li>
<p><strong>The Fix:</strong> We use a <strong>Maslow-Informed</strong> hierarchy to weight interests.</p>
</li>
<li>
<p><strong>Mathematical Resolution:</strong> Automation allows us to prioritize high-validity interests (<span style="font-family: &quot;Google Sans Text&quot;, sans-serif !important;">$85-100$</span> range) across both sides of a debate.</p>
</li>
</ul>
<hr />
<h2>The Automation Workflow</h2>
<p>Once we have scored data, the system performs <strong>Compatibility Analysis</strong> to find the "Resolution Floor":</p>
<table border="0">
<thead> 
<tr>
<td style="border-color: initial;"><strong>Step</strong></td>
<td style="border-color: initial;"><strong>Process</strong></td>
<td style="border-color: initial;"><strong>Result</strong></td>
</tr>
</thead> 
<tbody>
<tr>
<td style="border-color: initial;"><span style="font-family: &quot;Google Sans Text&quot;, sans-serif !important;"><strong>Extraction</strong></span></td>
<td style="border-color: initial;"><span style="font-family: &quot;Google Sans Text&quot;, sans-serif !important;">NLP pulls "whys" from raw debate text.</span></td>
<td style="border-color: initial;"><span style="font-family: &quot;Google Sans Text&quot;, sans-serif !important;">A list of raw interests.</span></td>
</tr>
<tr>
<td style="border-color: initial;"><span style="font-family: &quot;Google Sans Text&quot;, sans-serif !important;"><strong>Scoring</strong></span></td>
<td style="border-color: initial;"><span style="font-family: &quot;Google Sans Text&quot;, sans-serif !important;">Community/AI assigns <strong>Linkage</strong> and <strong>Validity</strong>.</span></td>
<td style="border-color: initial;"><span style="font-family: &quot;Google Sans Text&quot;, sans-serif !important;">A weighted priority list.</span></td>
</tr>
<tr>
<td style="border-color: initial;"><span style="font-family: &quot;Google Sans Text&quot;, sans-serif !important;"><strong>Clustering</strong></span></td>
<td style="border-color: initial;"><span style="font-family: &quot;Google Sans Text&quot;, sans-serif !important;">Grouping interests that are semantically identical.</span></td>
<td style="border-color: initial;"><span style="font-family: &quot;Google Sans Text&quot;, sans-serif !important;">Reduced noise; identified shared ground.</span></td>
</tr>
<tr>
<td style="border-color: initial;"><span style="font-family: &quot;Google Sans Text&quot;, sans-serif !important;"><strong>Optimization</strong></span></td>
<td style="border-color: initial;"><span style="font-family: &quot;Google Sans Text&quot;, sans-serif !important;">Solving for the "Maximum Shared Validity."</span></td>
<td style="border-color: initial;"><span style="font-family: &quot;Google Sans Text&quot;, sans-serif !important;">A proposal that satisfies the most critical needs of both sides.</span></td>
</tr>
</tbody>
</table>
<hr />
<h2>Why "Little" Conflicts Matter</h2>
<p>Large-scale polarization is just the sum of thousands of unaddressed "little" conflicts regarding definitions, motives, and evidence.</p>
<p>By automating the resolution of these small nodes:</p>
<ol start="1">
<li>
<p><strong>Trust is Built:</strong> Users see the system fairly scoring their core needs.</p>
</li>
<li>
<p><strong>Options are Invented:</strong> The system can suggest "Mutual Gain" options that humans, blinded by tribalism, usually miss.</p>
</li>
<li>
<p><strong>Consensus Becomes Default:</strong> Resolution becomes the path of least resistance rather than an exhausting uphill battle.</p>
</li>
</ol>
<blockquote>
<p><strong>Key Takeaway:</strong> We aren't just mapping interests for the sake of data; we are building a <strong>Conflict Operating System</strong> that can find the mathematical center of any debate.</p>
</blockquote>
<p>&nbsp;</p>
<p>&nbsp;</p>
