# Argument Extraction, Decomposition, and Scoring System

> **Complete specification for automatically extracting arguments from text, identifying conclusions and premises, classifying argument types, and scoring their strength.**

## Table of Contents

1. [Overview](#overview)
2. [Extracting Arguments From Natural Language](#1-extracting-arguments-from-natural-language)
3. [Deconstructing Arguments Using Formal Logic](#2-deconstructing-arguments-using-formal-logic)
4. [Argument Type Classification](#3-argument-type-classification-truth--importance--relevance)
5. [Grouping Arguments by Topic](#4-grouping-arguments-by-topic)
6. [Scoring Argument Strength](#5-scoring-argument-strength-0-100)
7. [Positivity/Negativity (Valence)](#6-positivity--negativity-valence)
8. [Data Output Format](#7-data-output-format-for-storage)
9. [Recommended Technical Methods](#8-recommended-technical-methods)
10. [Integration with ISE Framework](#9-integration-with-ise-framework)
11. [Implementation Steps](#10-implementation-steps)

---

## Overview

This specification enables automated extraction and analysis of arguments from natural language text. The system:

- **Extracts** arguments by identifying linguistic markers
- **Decomposes** arguments into premises and conclusions using formal logic notation
- **Classifies** arguments by type (Truth/Importance/Relevance)
- **Labels** argument roles (Linkage/Strengthener/Weakener)
- **Scores** argument strength (0-100) based on evidence quality and logical coherence
- **Measures** sentiment/valence (-100 to +100)
- **Groups** arguments by topic for organization

---

## 1. Extracting Arguments From Natural Language

### A. Identify Argumentative Sentences

Software should look for linguistic markers that indicate argumentative structure:

#### Conclusion Indicators

Words/phrases that signal a conclusion is being stated:

```
therefore, so, thus, hence, this means, my point is,
it follows that, we can conclude, consequently, as a result,
accordingly, for this reason, this shows that, this proves
```

#### Premise Indicators

Words/phrases that signal supporting evidence or reasons:

```
because, since, given that, due to, as a result of,
for the reason that, considering that, as, for,
seeing that, in light of, owing to
```

### B. Parse Argument Structure Using Examples

#### Example 1: Housing Affordability

**Input Text:**
> "Cities should allow more apartment construction **because** restrictive zoning increases rents."

**Extraction:**
- **Conclusion (C):** Cities should allow more apartment construction
- **Premise (P1):** Restrictive zoning increases rents

**Formal Notation:** `P1 â†’ C`

---

#### Example 2: Social Media Regulation

**Input Text:**
> "Teen mental health worsens with excessive social media use. **Therefore**, platforms should implement time-limit defaults."

**Extraction:**
- **Premise (P1):** Excessive use worsens teen mental health
- **Conclusion (C):** Platforms should implement time-limit defaults

**Formal Notation:** `P1 â†’ C`

---

#### Example 3: Climate Policy (Multi-premise)

**Input Text:**
> "Heatwaves have tripled in frequency over the past 40 years. This trend is linked to rising emissions. **Because of this**, governments should adopt stricter emissions targets."

**Extraction:**
- **Premise (P1):** Heatwaves have tripled in frequency
- **Premise (P2):** Trend is linked to rising emissions
- **Conclusion (C):** Governments should adopt stricter emissions targets

**Formal Notation:** `P1 âˆ§ P2 â†’ C`

### C. Multi-Sentence Arguments

Arguments frequently span multiple sentences. The extraction system must:

1. Identify sentence boundaries
2. Track context across sentences
3. Link related premises
4. Identify implicit connections

**Algorithm:**
1. Split text into sentences
2. Identify indicator words in each sentence
3. Build dependency graph between sentences
4. Extract complete argument structure

---

## 2. Deconstructing Arguments Using Formal Logic

### Notation System

Use standard logical notation:
- `P1, P2, P3...` = Premises
- `C` = Conclusion
- `âˆ§` = AND (conjunction)
- `â†’` = IMPLIES (implication)

**Standard Form:** `P1 âˆ§ P2 âˆ§ ... â†’ C`

### A. Identify Assertion Types

Each premise/conclusion can be labeled by its **role** in the argument:

#### 1. Linkage Assertions (subscript L)

**Purpose:** Directly connect premise to conclusion

**Pattern:** "If X, then Y" or causal connections

**Example (College Tuition):**
> "If college debt harms economic mobility, then tuition subsidies are justified."

- **P1â‚—:** College debt harms economic mobility â†’ tuition subsidies justified
- **C:** Tuition subsidies are justified

---

#### 2. Strengtheners (subscript S)

**Purpose:** Add credibility, precision, or supporting evidence to existing premises

**Pattern:** Additional evidence, expert consensus, empirical data

**Example:**
> "Multiple independent studies confirm this effect."

- **P1â‚›:** Studies confirm the effect [strengthens another premise]

---

#### 3. Weakeners (subscript W)

**Purpose:** Challenge, limit, or add caveats to premises

**Pattern:** Counterevidence, scope limitations, conditions

**Example:**
> "However, this effect is smaller in high-income households."

- **P1w:** Effect is smaller in certain contexts [weakens scope]

---

### B. Mark Assertions in Notation

#### Example: Renewable Energy

**Input Text:**
> "Solar power reduces long-term electricity prices because once installed, costs remain stable. Historical price data supports this."

**Extraction:**
- **P1â‚—:** Stable operating costs â†’ lower long-term prices (Linkage)
- **P2â‚›:** Historical data supports this (Strengthener)
- **C:** Solar reduces long-term electricity prices

**Formal Notation:** `P1â‚— âˆ§ P2â‚› â†’ C`

---

## 3. Argument Type Classification: Truth / Importance / Relevance

Every argument falls into one of three categories:

### A. Truth Arguments (subscript T)

**Purpose:** Describe what **is** true about the world

**Pattern:** Factual claims, empirical statements, testable hypotheses

**Example (Healthcare Reform):**
> "Preventive care reduces long-term medical costs."

- **Type:** Truth (T)
- **Test:** Can be verified through studies/data

---

### B. Importance Arguments (subscript I)

**Purpose:** Describe why something **matters**

**Pattern:** Value judgments, priority claims, significance statements

**Example (Corporate Taxation):**
> "Fair contribution to public goods is essential for a stable society."

- **Type:** Importance (I)
- **Test:** Based on values, not empirical facts

---

### C. Relevance Arguments (subscript R)

**Purpose:** Describe whether a premise **actually connects** to a conclusion

**Pattern:** Logical relevance, scope limitations, applicability

**Example (Social Media):**
> "Screen-time limits are irrelevant unless enforceable across apps."

- **Type:** Relevance (R)
- **Test:** Questions whether a premise actually supports the conclusion

---

### Combined Example

**Argument:**
> "Preventive care reduces costs (Truth). This matters because healthcare spending threatens government budgets (Importance). However, preventive care only helps if patients actually use it (Relevance)."

**Notation:** `P1áµ€ âˆ§ P2á´µ âˆ§ P3á´¿ â†’ C`

---

## 4. Grouping Arguments by Topic

### Topic Hierarchy

Arguments should be assigned to the **most specific** applicable topic using hierarchical classification:

```
Topic Tree Structure:
â”œâ”€â”€ Climate Policy
â”‚   â”œâ”€â”€ Mitigation
â”‚   â”‚   â”œâ”€â”€ Emissions Targets
â”‚   â”‚   â””â”€â”€ Carbon Pricing
â”‚   â””â”€â”€ Adaptation
â”œâ”€â”€ Housing
â”‚   â”œâ”€â”€ Affordability
â”‚   â”‚   â”œâ”€â”€ Zoning
â”‚   â”‚   â””â”€â”€ Rent Control
â”‚   â””â”€â”€ Homelessness
â”œâ”€â”€ Technology
â”‚   â”œâ”€â”€ Social Media
â”‚   â”‚   â”œâ”€â”€ Child Safety
â”‚   â”‚   â””â”€â”€ Misinformation
â”‚   â””â”€â”€ AI
â”œâ”€â”€ Economy
â”‚   â”œâ”€â”€ Welfare
â”‚   â”‚   â”œâ”€â”€ UBI
â”‚   â”‚   â””â”€â”€ Food Stamps
â”‚   â””â”€â”€ Labor
â””â”€â”€ Healthcare
    â”œâ”€â”€ Insurance
    â”‚   â””â”€â”€ Preventive Care
    â””â”€â”€ Drug Pricing
```

### Example Groupings

| Argument | Topic Path |
|----------|------------|
| "Restrictive zoning increases rents" | Housing / Affordability / Zoning |
| "UBI reduces poverty" | Economy / Welfare / UBI |
| "Social media harms teen mental health" | Technology / Social Media / Child Safety |
| "Carbon tax reduces emissions" | Climate Policy / Mitigation / Carbon Pricing |

---

## 5. Scoring Argument Strength (0-100)

Argument strength is based on multiple factors:

### A. Internal Logical Coherence

**Criteria:**
- Valid logical structure
- No logical fallacies (ad hominem, straw man, false dichotomy, etc.)
- Premises actually support conclusion

**Scoring:**
- Valid structure: +40 points
- No major fallacies: +10 points
- Strong premise-conclusion link: +10 points

---

### B. Evidence Quality (Truth Arguments)

Evidence is classified into **4 tiers**:

#### Tier 1: Highest Quality (Score: 90-100)
- Meta-analyses
- Systematic reviews
- Peer-reviewed studies in top journals
- Replicated findings

#### Tier 2: High Quality (Score: 70-89)
- Expert analysis
- Institutional reports (IMF, World Bank, WHO)
- Single peer-reviewed studies
- Government statistical agencies

#### Tier 3: Medium Quality (Score: 40-69)
- Large-N surveys
- Investigative journalism
- Industry reports
- Expert opinion pieces

#### Tier 4: Low Quality (Score: 10-39)
- Anecdotes
- Personal experiences
- Opinion pieces
- Blog posts
- Unverified claims

**Note:** Evidence tier directly influences base score for Truth arguments.

---

### C. Value Clarity (Importance Arguments)

**Criteria:**
- Universality (how widely shared is this value?)
- Moral intuitiveness (how self-evident?)
- Consistency with other values

**Scoring:**
- Universal values (human rights, fairness): 80-100
- Widely shared values (economic growth, security): 60-79
- Contested values (individualism vs. collectivism): 40-59
- Niche values: 20-39

---

### D. Conceptual Directness (Relevance Arguments)

**Criteria:**
- How many inferential steps between premise and conclusion?
- Are there hidden assumptions?
- Is the connection clear and direct?

**Scoring:**
- Direct connection (1 step): 80-100
- Moderate connection (2-3 steps): 60-79
- Weak connection (4+ steps): 40-59
- Tenuous connection: 20-39

---

### E. Strengtheners / Weakeners

Modifiers adjust base score:

**Strengtheners:**
- Additional confirming evidence: +5 to +10
- Expert consensus: +5 to +10
- Replication: +5
- Large effect size: +5

**Weakeners:**
- Contradicting evidence: -5 to -10
- Expert disagreement: -5 to -10
- Small sample size: -5
- Scope limitations: -5

---

### F. Topic-Internal Normalization

**Within each topic**, normalize scores so:
- **Strongest argument = 100**
- Other arguments scaled proportionally

**Example (Topic: "Legalizing ADUs"):**
1. "ADUs increase housing supply without changing neighborhood character" â†’ 100 (strongest)
2. "ADUs reduce rental prices in expensive cities" â†’ 87
3. "ADUs allow multigenerational living" â†’ 74
4. "ADUs can be built faster than apartments" â†’ 62

---

## 6. Positivity / Negativity (Valence)

**Valence** measures whether an argument **supports** or **opposes** the belief.

### Scale: -100 to +100

- **+100:** Strongly supports the belief
- **+50:** Moderately supports
- **0:** Neutral (neither supports nor opposes)
- **-50:** Moderately opposes
- **-100:** Strongly opposes

### Examples

**Topic:** "Cities should allow more housing construction"

| Argument | Valence | Score |
|----------|---------|-------|
| "Restrictive zoning increases rents" | +70 | Strong support |
| "More housing improves affordability" | +85 | Very strong support |
| "Increasing density strains infrastructure" | -55 | Moderate opposition |
| "Construction creates neighborhood disruption" | -40 | Mild opposition |
| "Different cities define ADUs differently" | 0 | Neutral (descriptive) |

---

## 7. Data Output Format (for storage)

### JSON Schema

Each extracted argument should be stored with the following fields:

```json
{
  "topic": "Housing Affordability / Zoning",
  "conclusion": "Cities should allow more housing construction",
  "premises": [
    {
      "text": "Restrictive zoning increases rents",
      "role": "linkage",
      "type": "truth",
      "evidenceTier": 1
    }
  ],
  "argumentType": "truth",
  "mainRole": "linkage",
  "strengthScore": 91,
  "valence": 80,
  "evidenceTier": 1,
  "notation": "P1â‚—áµ€ â†’ C",
  "source": {
    "url": "https://example.com/study",
    "author": "Researcher Name",
    "date": "2024-01-15"
  },
  "extractedFrom": "Original text containing the argument...",
  "confidence": 0.89
}
```

### Field Definitions

| Field | Type | Description | Example |
|-------|------|-------------|---------|
| `topic` | String | Topic path | "Housing / Affordability / Zoning" |
| `conclusion` | String | Main claim | "Cities should allow more housing" |
| `premises` | Array | Supporting premises | [{ text, role, type }] |
| `argumentType` | Enum | T/I/R | "truth" |
| `mainRole` | Enum | L/S/W | "linkage" |
| `strengthScore` | Number | 0-100 | 91 |
| `valence` | Number | -100 to +100 | 80 |
| `evidenceTier` | Number | 1-4 | 1 |
| `notation` | String | Formal logic | "P1â‚—áµ€ â†’ C" |
| `source` | Object | Citation info | { url, author, date } |
| `extractedFrom` | String | Original text | Full source text |
| `confidence` | Number | 0-1 | 0.89 |

---

## 8. Recommended Technical Methods

### A. Extraction Tools

#### Pattern-Based Extraction (Simple, Fast)
```javascript
// Regex patterns for indicator words
const conclusionIndicators = /\b(therefore|thus|hence|so|consequently)\b/i;
const premiseIndicators = /\b(because|since|given that|due to)\b/i;
```

#### NLP Libraries (Advanced)

**spaCy (Python):**
- Dependency parsing
- Named entity recognition
- Sentence segmentation

**Natural (Node.js):**
- Tokenization
- Part-of-speech tagging
- Sentence splitting

**Compromise (Node.js):**
- Lightweight NLP
- Pattern matching
- Fast processing

---

### B. Classification Tools

#### Supervised ML Models

**For Truth/Importance/Relevance Classification:**

1. **Training Dataset:**
   - Label 500+ arguments manually
   - Balance across T/I/R categories
   - Include diverse topics

2. **Model Options:**
   - **BERT** fine-tuning (high accuracy, slower)
   - **FastText** (fast, good for large datasets)
   - **Logistic Regression** (simple baseline)

3. **Features:**
   - Linguistic patterns (modal verbs, epistemic markers)
   - Semantic embeddings (sentence-BERT)
   - Context (surrounding sentences)

---

#### Evidence Tier Classification

**Rule-Based Approach:**

```javascript
function classifyEvidenceTier(source) {
  if (isPeerReviewed(source) || isMetaAnalysis(source)) return 1;
  if (isInstitutionalReport(source) || isGovernmentData(source)) return 2;
  if (isJournalismReport(source) || isLargeSurvey(source)) return 3;
  return 4; // Anecdotal/opinion
}
```

**ML Approach:**
- Train classifier on source metadata (domain, author credentials, publication type)
- Use domain reputation scores (e.g., SciMago Journal Rank)

---

### C. Scoring Tools

#### Strength Score Calculation

```javascript
function calculateStrengthScore(argument) {
  let score = 50; // Base score

  // Evidence quality
  score += evidenceTierBonus[argument.evidenceTier];

  // Logical coherence
  if (isValidLogic(argument)) score += 20;
  if (!hasFallacies(argument)) score += 10;

  // Strengtheners/weakeners
  argument.strengtheners.forEach(s => score += s.weight);
  argument.weakeners.forEach(w => score -= w.weight);

  // Normalize to 0-100
  return Math.max(0, Math.min(100, score));
}
```

#### Topic Normalization

```javascript
function normalizeScoresForTopic(arguments, topic) {
  const topicArgs = arguments.filter(a => a.topic === topic);
  const maxScore = Math.max(...topicArgs.map(a => a.rawScore));

  topicArgs.forEach(arg => {
    arg.normalizedScore = (arg.rawScore / maxScore) * 100;
  });
}
```

---

## 9. Integration with ISE Framework

This specification integrates with existing ISE components:

### Links to ISE Documentation

| Component | Integration Point | ISE Docs |
|-----------|-------------------|----------|
| **Arguments** | Store extracted arguments | [Argument Model](../backend/models/Argument.js) |
| **Evidence Tiers** | Classify sources by quality | [Evidence Model](../backend/models/Evidence.js) |
| **Topic Classification** | Group by topic hierarchy | [Taxonomy Service](../backend/services/taxonomyService.js) |
| **Strength Scoring** | Existing strength scorer | [Strength Service](../backend/services/strengthScoringService.js) |
| **ReasonRank** | Network-based scoring | [ReasonRank Algorithm](./wiki/ReasonRank.md) |
| **Belief Organization** | Organize by topic/strength | [Belief Organization](./BELIEF_ORGANIZATION_SYSTEM.md) |

### Integration Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     INPUT: Natural Language Text                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ArgumentExtractionService                           â”‚
â”‚  â€¢ Detect indicator words (because, therefore)                   â”‚
â”‚  â€¢ Extract premises and conclusions                              â”‚
â”‚  â€¢ Parse multi-sentence arguments                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ArgumentDecomposerService                           â”‚
â”‚  â€¢ Create formal logic notation (P1 âˆ§ P2 â†’ C)                   â”‚
â”‚  â€¢ Label roles (Linkage/Strengthener/Weakener)                   â”‚
â”‚  â€¢ Identify premise dependencies                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ArgumentClassifierService                           â”‚
â”‚  â€¢ Classify type (Truth/Importance/Relevance)                    â”‚
â”‚  â€¢ Determine evidence tier (1-4)                                 â”‚
â”‚  â€¢ Calculate valence (-100 to +100)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              StrengthScoringService (Enhanced)                   â”‚
â”‚  â€¢ Calculate base strength (0-100)                               â”‚
â”‚  â€¢ Apply strengtheners/weakeners                                 â”‚
â”‚  â€¢ Normalize within topic                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TaxonomyService                                     â”‚
â”‚  â€¢ Assign to topic hierarchy                                     â”‚
â”‚  â€¢ Link to related arguments                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Store in Argument Model                             â”‚
â”‚  â€¢ Save to database                                              â”‚
â”‚  â€¢ Update ReasonRank scores                                      â”‚
â”‚  â€¢ Link to belief and evidence                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 10. Implementation Steps

### Phase 1: Core Extraction (Weeks 1-2)

**Tasks:**
1. âœ… Create `ArgumentExtractionService.js`
   - Implement indicator word detection
   - Build sentence parser
   - Extract premise-conclusion pairs

2. âœ… Create training dataset
   - 100+ labeled examples across topics
   - Balanced across T/I/R types
   - Include edge cases

3. âœ… Basic unit tests
   - Test extraction accuracy
   - Validate output format

---

### Phase 2: Decomposition & Classification (Weeks 3-4)

**Tasks:**
1. âœ… Create `ArgumentDecomposerService.js`
   - Formal logic notation generator
   - Role labeling (L/S/W)
   - Premise dependency tracking

2. âœ… Create `ArgumentClassifierService.js`
   - T/I/R classification model
   - Evidence tier classifier
   - Valence scoring

3. âœ… Update `Argument.js` model
   - Add new fields (premises, conclusion, type, role, etc.)
   - Migration script for existing data

---

### Phase 3: Scoring & Integration (Weeks 5-6)

**Tasks:**
1. âœ… Enhance `StrengthScoringService.js`
   - Add evidence tier weighting
   - Implement strengthener/weakener logic
   - Topic-internal normalization

2. âœ… Create API endpoints
   - POST `/api/arguments/extract` - Extract from text
   - POST `/api/arguments/classify` - Classify existing arguments
   - GET `/api/arguments/topic/:topicId` - Get by topic with scores

3. âœ… Integration testing
   - End-to-end extraction pipeline
   - Performance testing (100+ arguments)

---

### Phase 4: Advanced Features (Weeks 7-8)

**Tasks:**
1. ðŸ”„ ML model training
   - Fine-tune BERT for T/I/R classification
   - Train evidence tier classifier
   - Optimize for accuracy

2. ðŸ”„ Batch processing
   - Process multiple documents
   - Wikipedia article extraction
   - News article processing

3. ðŸ”„ UI Integration
   - Argument extraction form
   - Visual argument tree display
   - Strength score visualization

---

### Phase 5: Optimization & Deployment (Weeks 9-10)

**Tasks:**
1. ðŸ“‹ Performance optimization
   - Caching for common patterns
   - Parallel processing
   - Database indexing

2. ðŸ“‹ Documentation
   - API documentation
   - User guides
   - Developer tutorials

3. ðŸ“‹ Deployment
   - Production deployment
   - Monitoring setup
   - Error tracking

---

## Example Use Cases

### Use Case 1: Extract from Wikipedia Article

**Input:**
```
Extract arguments from: "Minimum wage laws establish a base level of pay
that employers must provide. Research shows higher minimum wages reduce
poverty. However, some studies find negative employment effects in certain
sectors. Therefore, policymakers must balance poverty reduction against
potential job losses."
```

**Output:**
```json
{
  "arguments": [
    {
      "conclusion": "Higher minimum wages reduce poverty",
      "premises": [
        { "text": "Research shows higher minimum wages reduce poverty", "role": "linkage" }
      ],
      "type": "truth",
      "strengthScore": 78,
      "valence": 85,
      "evidenceTier": 2
    },
    {
      "conclusion": "Minimum wage may cause job losses",
      "premises": [
        { "text": "Some studies find negative employment effects", "role": "linkage" }
      ],
      "type": "truth",
      "strengthScore": 65,
      "valence": -70,
      "evidenceTier": 2
    },
    {
      "conclusion": "Policymakers must balance tradeoffs",
      "premises": [
        { "text": "Poverty reduction vs. job losses", "role": "linkage" }
      ],
      "type": "importance",
      "strengthScore": 70,
      "valence": 0,
      "evidenceTier": 3
    }
  ]
}
```

---

### Use Case 2: Classify Existing Argument

**Input:**
```
Classify this argument:
"Universal healthcare is essential because access to medical care is a
fundamental human right."
```

**Output:**
```json
{
  "type": "importance",
  "role": "linkage",
  "premises": [
    {
      "text": "Access to medical care is a fundamental human right",
      "type": "importance",
      "role": "linkage"
    }
  ],
  "conclusion": "Universal healthcare is essential",
  "strengthScore": 75,
  "valence": 90,
  "evidenceTier": 4,
  "notation": "P1â‚—á´µ â†’ C"
}
```

---

## Success Metrics

### Accuracy Targets

| Metric | Target | Measurement |
|--------|--------|-------------|
| Extraction Accuracy | >85% | Manual validation of 100 random extractions |
| T/I/R Classification | >80% | F1 score on test set |
| Evidence Tier Classification | >75% | Agreement with expert ratings |
| Strength Score Consistency | >70% | Correlation with human ratings |

### Performance Targets

| Metric | Target |
|--------|--------|
| Extraction Speed | <500ms per argument |
| Batch Processing | >100 arguments/minute |
| API Response Time | <1 second |

---

## References

### Academic Literature

1. **Argument Mining:**
   - Stab & Gurevych (2017) - "Parsing Argumentation Structures in Persuasive Essays"
   - Lippi & Torroni (2016) - "Argumentation Mining: State of the Art and Emerging Trends"

2. **Natural Language Processing:**
   - Devlin et al. (2019) - "BERT: Pre-training of Deep Bidirectional Transformers"
   - Manning & SchÃ¼tze (1999) - "Foundations of Statistical NLP"

3. **Logic & Reasoning:**
   - Toulmin (1958) - "The Uses of Argument"
   - Walton (1996) - "Argumentation Schemes for Presumptive Reasoning"

### Related ISE Documentation

- [Architecture Overview](./ARCHITECTURE.md)
- [Belief Organization System](./BELIEF_ORGANIZATION_SYSTEM.md)
- [ReasonRank Algorithm](./wiki/ReasonRank.md)
- [Scoring System](./wiki/Scoring-System.md)
- [Integration Guide](./INTEGRATION_GUIDE.md)

---

## Contributing

To contribute to argument extraction system development:

1. Read this specification thoroughly
2. Review existing [Argument Model](../backend/models/Argument.js)
3. Check [open issues](https://github.com/myklob/ideastockexchange/issues) for tasks
4. Submit pull requests following [contribution guidelines](../CONTRIBUTING.md)

---

## Contact & Support

- **GitHub:** [@myklob](https://github.com/myklob)
- **Issues:** [Report bugs or request features](https://github.com/myklob/ideastockexchange/issues)
- **Discussions:** [Join the conversation](https://github.com/myklob/ideastockexchange/discussions)

---

**Last Updated:** 2025-01-29
**Status:** âœ… Specification Complete | ðŸ”„ Implementation In Progress
**Version:** 1.0.0
