I believe the most elegant way to come up with a linkage score would be to just make a new argument, that “a” supports “b”, with all the normal reasons to agree and disagree. However, I also propose the percentage of up-votes compared to the percentage of down-votes and other good idea promoting algorithms below.

Also, without editors, you would run into the problem of duplication. If we had this at the time of the Gulf Wars, people could have been submitting the belief that Saddam Hussein was a bad person as a reason to support the belief that we should go to war. People would submit the belief that we don’t go to war with everyone who is bad, as a way of weakening the linkage between this conclusion and argument. But someone might also submit the belief that he was “evil”. How much is the world “evil” and “bad” the same thing? Is Evil just a worse kind of bad? These questions could be quantified, if for each argument, we brainstormed a list of “other ways of saying the same thing”. Of course we would use all of our algorithms to determine to what degree they are the same thing. If we determine that two items are 85% the same thing, then when both of them are used as reasons to support the same thing, then they would only count as 1.15x their two scores, not 2x.

# Forms #

There will be slightly different forms for evaluating the different types of argument, because specific questions can be tailored to promote better quality depending on the type of argument being made.

For instance, a photo submitted as a reason to agree or disagree might have different issues that need to be addressed related to exaggeration of political cartoons, or appeal to emotion.

The following equation could be used to add more points to valid linkages between assumptions, arguments, and conclusions.